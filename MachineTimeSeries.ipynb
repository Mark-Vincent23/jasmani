{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Library Import"
      ],
      "metadata": {
        "id": "YSBeA5naopmH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tALXFcl5oU4h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "import shutil\n",
        "\n",
        "\n",
        "print(\"🚀 Building 5-Months Input Model - EXACT SAME as create_working_model...\")\n",
        "print(f\"🧠 TensorFlow: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "GFK7ZvJqozeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Data Garjas Unhan - Sheet1 fix.csv')\n",
        "df['BULAN'] = pd.to_datetime(df['BULAN'], dayfirst=True)\n",
        "df = df.sort_values(['ID', 'BULAN'])\n",
        "\n",
        "features = ['PUSH UP', 'PULL UP', 'LARI 12 MENIT', 'SIT UP ', 'SHUTTLE RUN']"
      ],
      "metadata": {
        "id": "zmpw_Fuyo6rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Script ini berfungsi untuk membaca dataset dari file CSV, mengonversi kolom 'BULAN' ke format datetime agar dapat digunakan untuk analisis berbasis waktu, mengurutkan data berdasarkan 'ID' dan 'BULAN' untuk memastikan setiap entri tersusun secara kronologis, serta mendefinisikan daftar fitur (features) yang terdiri dari berbagai aktivitas fisik seperti 'PUSH UP', 'PULL UP', 'LARI 12 MENIT', 'SIT UP ', dan 'SHUTTLE RUN' untuk digunakan dalam analisis atau model machine learning."
      ],
      "metadata": {
        "id": "sQCfbZzqpE91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "cK9V6tGHqFgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean data"
      ],
      "metadata": {
        "id": "JJAJyYvdqnfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in features:\n",
        "    df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.'), errors='coerce')\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "data = df[features].copy()\n",
        "print(f\"✅ Data loaded: {data.shape}\")\n"
      ],
      "metadata": {
        "id": "sbaY7dXxpEMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Script ini berfungsi untuk memastikan bahwa kolom-kolom dalam daftar features memiliki tipe data numerik dengan mengganti tanda koma (,) menjadi titik (.) untuk format angka, mengonversi nilai ke tipe numerik, dan menangani nilai yang tidak valid dengan mengganti mereka menjadi NaN. Baris dengan nilai kosong (NaN) kemudian dihapus menggunakan dropna(). Setelah itu, data yang bersih disalin ke variabel data, dan ukuran data (jumlah baris dan kolom) ditampilkan untuk memastikan data telah berhasil dimuat dan siap digunakan dalam analisis atau model machine learning."
      ],
      "metadata": {
        "id": "tReTWKAuqAB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scale data"
      ],
      "metadata": {
        "id": "QD5tTZ7_qxgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(data)\n",
        "print(f\"✅ Data scaled: {scaled.shape}\")\n"
      ],
      "metadata": {
        "id": "wbO638RJqLLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Script ini berfungsi untuk melakukan normalisasi data menggunakan MinMaxScaler, yang mengubah nilai dalam dataset menjadi rentang antara 0 dan 1. Data yang telah dibersihkan (data) diproses dengan fit_transform() untuk menghitung skala minimum dan maksimum, lalu menerapkan transformasi pada semua nilai. Hasilnya disimpan dalam variabel scaled, dan ukuran data yang telah dinormalisasi ditampilkan untuk memastikan proses scaling berhasil dilakukan. Normalisasi ini penting untuk memastikan fitur memiliki skala yang seragam, terutama dalam algoritma machine learning yang sensitif terhadap perbedaan skala antar fitur."
      ],
      "metadata": {
        "id": "wZ0E3MCLqc7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create REAL DATA sequences dari 500 students"
      ],
      "metadata": {
        "id": "fgsujS42rJe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"📊 Creating REAL sequences from 500 students...\")\n",
        "X_sequences = []\n",
        "y_sequences = []"
      ],
      "metadata": {
        "id": "ca249LLNqiQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Script ini berfungsi untuk memulai proses pembuatan sequences (urutan data) dari 500 siswa berdasarkan data yang telah diproses sebelumnya. Variabel X_sequences digunakan untuk menyimpan fitur input (sequences), sedangkan y_sequences digunakan untuk menyimpan target atau label yang sesuai dengan setiap sequence. Proses ini biasanya dilakukan untuk membentuk data dalam format time-series atau sequential data yang diperlukan untuk model seperti Recurrent Neural Networks (RNN) atau Long Short-Term Memory (LSTM)."
      ],
      "metadata": {
        "id": "1S-NKzf1rVmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formating Data"
      ],
      "metadata": {
        "id": "82Wl06bWrfWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for student_id, student_data in df.groupby('ID'):\n",
        "    try:\n",
        "        student_num = int(student_id[1:])  # P001 → 1\n",
        "        student_data = student_data.sort_values('BULAN').reset_index(drop=True)\n",
        "\n",
        "        if len(student_data) >= 6:  # Need 6 months: 5 input + 1 target\n",
        "            values = student_data[features].values\n",
        "            scaled_values = scaler.transform(values)\n",
        "\n",
        "            # Create sequence: Month 1-5 → Month 6\n",
        "            X_sequences.append(scaled_values[0:5])  # First 5 months\n",
        "            y_sequences.append(scaled_values[5])    # 6th month\n",
        "\n",
        "            # If more than 6 months, create additional sequences\n",
        "            for i in range(1, len(scaled_values) - 5):\n",
        "                X_sequences.append(scaled_values[i:i+5])\n",
        "                y_sequences.append(scaled_values[i+5])\n",
        "\n",
        "    except (ValueError, IndexError):\n",
        "        continue\n",
        "\n",
        "X_real = np.array(X_sequences) if X_sequences else np.array([]).reshape(0, 5, 5)\n",
        "y_real = np.array(y_sequences) if y_sequences else np.array([]).reshape(0, 5)\n",
        "\n",
        "print(f\"✅ REAL sequences: X={X_real.shape}, y={y_real.shape}\")\n"
      ],
      "metadata": {
        "id": "XaObhLmsrW9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Script ini bertujuan untuk membentuk data dalam format time-series atau sequential data, di mana lima bulan pertama digunakan sebagai input untuk memprediksi bulan keenam. Data ini dapat digunakan untuk melatih model seperti RNN atau LSTM yang membutuhkan data berurutan."
      ],
      "metadata": {
        "id": "mP66QhsArnr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"📊 Adding synthetic data with TREND logic...\")\n",
        "np.random.seed(42)\n",
        "synthetic_X = []\n",
        "synthetic_y = []\n"
      ],
      "metadata": {
        "id": "IaXAbxoqsoni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bagian ini adalah awal dari proses pembuatan data sintetis menggunakan logika trend. Berikut adalah penjelasan:\n",
        "\n",
        "**Penjelasan Tujuan:**\n",
        "\n",
        " - Membuat data tambahan (sintetis) untuk melengkapi data asli jika jumlah data real tidak mencukupi.\n",
        "Data sintetis dibuat dengan pola trend naik (UP) atau trend turun (DOWN) untuk mensimulasikan perubahan nilai dari bulan ke bulan.\n",
        "\n",
        "- np.random.seed(42): Menetapkan seed untuk memastikan hasil random tetap konsisten setiap kali script dijalankan.\n",
        "synthetic_X: List untuk menyimpan input data sintetis (5 bulan pertama).\n",
        "synthetic_y: List untuk menyimpan target data sintetis (bulan ke-6).\n",
        "Proses Selanjutnya: Setelah inisialisasi, script akan membuat 500 sequences sintetis menggunakan logika trend, seperti:\n",
        "\n",
        "- Trend Naik (UP): Nilai meningkat 2-6% setiap bulan.\n",
        "Trend Turun (DOWN): Nilai menurun 1-4% setiap bulan.\n",
        "Ditambahkan noise untuk membuat data lebih realistis.\n",
        "\n",
        "**Kesimpulan**\n",
        "\n",
        "- Bagian ini mempersiapkan variabel untuk membuat data sintetis yang akan digunakan bersama data real dalam pelatihan model LSTM. Data sintetis ini membantu meningkatkan jumlah data pelatihan dan memperbaiki generalisasi model.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZEc-rBFEtCoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate 500 synthetic sequences\n",
        "for i in range(500):\n",
        "    # Pick random base from real scaled data\n",
        "    if len(scaled) > 0:\n",
        "        base_idx = np.random.randint(0, len(scaled))\n",
        "        base = scaled[base_idx].copy()\n",
        "    else:\n",
        "        base = np.random.uniform(0.3, 0.7, 5)  # Fallback\n",
        "\n",
        "    # Determine trend: 60% UP, 40% DOWN (simulate ID 1-250 vs 251-500)\n",
        "    trend_type = 1 if i < 180 else 0  # 180 UP, 120 DOWN\n",
        "\n",
        "    # Create 6-month sequence with trend\n",
        "    sequence = []\n",
        "    for step in range(6):\n",
        "        if step == 0:\n",
        "            current = base.copy()\n",
        "        else:\n",
        "            prev = sequence[step-1]\n",
        "            if trend_type == 1:  # UP trend (like ID 1-250)\n",
        "                change = np.random.uniform(0.02, 0.06)  # 2-6% increase per month\n",
        "                current = prev * (1 + change)\n",
        "            else:  # DOWN trend (like ID 251-500)\n",
        "                change = np.random.uniform(0.01, 0.04)  # 1-4% decrease per month\n",
        "                current = prev * (1 - change)\n",
        "\n",
        "            # Add realistic noise\n",
        "            noise = np.random.normal(1, 0.015, len(current))\n",
        "            current = current * noise\n",
        "            current = np.clip(current, 0, 1)  # Keep normalized\n",
        "\n",
        "        sequence.append(current)\n",
        "\n",
        "    # Input: first 5 months, Target: 6th month\n",
        "    synthetic_X.append(np.array(sequence[:5]))\n",
        "    synthetic_y.append(sequence[5])"
      ],
      "metadata": {
        "id": "XtFIiUcu0Kx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kesimpulan:**\n",
        "\n",
        "- Script ini mensimulasikan data sintetis dengan pola trend naik dan trend turun, menambahkan noise untuk membuat data lebih realistis, dan memastikan data tetap ter-normalisasi. Data ini digunakan untuk melengkapi data real dalam pelatihan model."
      ],
      "metadata": {
        "id": "Gje5OfS12kaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if len(X_real) > 0:\n",
        "    X = np.vstack([X_real, synthetic_X])\n",
        "    y = np.vstack([y_real, synthetic_y])\n",
        "else:\n",
        "    X = np.array(synthetic_X)\n",
        "    y = np.array(synthetic_y)\n",
        "\n",
        "print(f\"✅ Combined sequences: X={X.shape}, y={y.shape}\")\n",
        "print(f\"📊 Real sequences: {len(X_real)}\")\n",
        "print(f\"📊 Synthetic sequences: {len(synthetic_X)}\")"
      ],
      "metadata": {
        "id": "4MHIc3qa2z4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kesimpulan:**\n",
        "\n",
        "- Script ini memastikan bahwa dataset pelatihan mencakup data real dan sintetis. Jika data real tidak mencukupi, data sintetis akan melengkapi dataset untuk memastikan model memiliki cukup data untuk dilatih."
      ],
      "metadata": {
        "id": "T9JgELyx3eSQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Membuat Model"
      ],
      "metadata": {
        "id": "l5WTrx9L3yZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model LSTM"
      ],
      "metadata": {
        "id": "mYUZqS4r34R1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n🧠 Building model - SAME as create_working_model but INPUT(5,5)...\")\n",
        "model = Sequential([\n",
        "    Input(shape=(5, 5), name='input_layer'),                    # CHANGED: (5,5) instead of (3,5)\n",
        "    LSTM(64, activation='relu', return_sequences=False, name='lstm_layer'),  # SAMA\n",
        "    Dense(32, activation='relu', name='hidden_layer'),          # SAMA\n",
        "    Dense(5, activation='linear', name='output_layer')          # SAMA\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])    # SAMA\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "k7BhH77W3oPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Script ini membangun model LSTM (Long Short-Term Memory) menggunakan arsitektur Sequential untuk memproses data urutan (time-series) dengan input berbentuk (5, 5) (5 bulan × 5 fitur). Model terdiri dari tiga lapisan utama: Input Layer untuk menerima data dengan bentuk (5, 5), LSTM Layer dengan 64 unit untuk menangkap pola temporal dalam data, dan dua Dense Layers (lapisan tersembunyi dengan 32 unit dan lapisan keluaran dengan 5 unit) untuk menghasilkan prediksi 5 fitur pada bulan ke-6. Model dikompilasi menggunakan optimizer Adam, fungsi loss Mean Squared Error (MSE) untuk regresi, dan metrik evaluasi Mean Absolute Error (MAE). Fungsi model.summary() memberikan ringkasan struktur model dan jumlah parameter yang dilatih."
      ],
      "metadata": {
        "id": "S3YN-DKs3_Yu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "d0ldBYl24T_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🚀 Training model on 5-month sequences...\")\n",
        "history = model.fit(\n",
        "    X, y,\n",
        "    epochs=100,         # SAMA\n",
        "    batch_size=32,      # SAMA\n",
        "    validation_split=0.2,  # SAMA\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "5pRJdOTM4CHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Script ini melatih model LSTM menggunakan data input (X) dan target (y) dengan konfigurasi pelatihan selama 100 epoch, ukuran batch 32, dan membagi 20% data sebagai validation set untuk mengevaluasi performa model selama pelatihan. Fungsi model.fit() menjalankan proses pelatihan dengan menampilkan log hasil setiap epoch karena parameter verbose=1. Proses ini bertujuan untuk mengoptimalkan bobot model agar dapat memprediksi 5 fitur bulan ke-6 berdasarkan data 5 bulan sebelumnya. Hasil pelatihan disimpan dalam variabel history, yang dapat digunakan untuk analisis lebih lanjut, seperti memvisualisasikan loss dan metrik evaluasi."
      ],
      "metadata": {
        "id": "OuzHSDMj4W-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Model"
      ],
      "metadata": {
        "id": "aYLBjV-x4nME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membuat Directori"
      ],
      "metadata": {
        "id": "OSu5zmtr5A4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "backend_dir = '../backend/model'\n",
        "if os.path.exists(backend_dir):\n",
        "    shutil.rmtree(backend_dir)\n",
        "os.makedirs(backend_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "uJeLMnJj4aLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Script ini membuat direktori untuk menyimpan model yang telah dilatih di lokasi ../backend/model. Jika direktori tersebut sudah ada, maka akan dihapus terlebih dahulu menggunakan shutil.rmtree() untuk memastikan tidak ada file lama yang tersisa. Setelah itu, direktori baru dibuat menggunakan os.makedirs() dengan parameter exist_ok=True, yang memastikan tidak ada error jika direktori sudah ada. Langkah ini memastikan bahwa direktori penyimpanan model bersih dan siap digunakan untuk menyimpan file model, seperti arsitektur, bobot, dan scaler."
      ],
      "metadata": {
        "id": "Mc5ZHLj64x7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model"
      ],
      "metadata": {
        "id": "jLSFhax167e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Save model weights (SAMA)\n",
        "model.save_weights(f'{backend_dir}/model_weights.h5')\n",
        "print(\"✅ Model weights saved\")\n",
        "\n",
        "# 2. Save model architecture (SAMA)\n",
        "model_json = model.to_json()\n",
        "with open(f'{backend_dir}/model_architecture.json', 'w') as f:\n",
        "    json.dump(json.loads(model_json), f, indent=2)\n",
        "print(\"✅ Model architecture saved\")\n",
        "\n",
        "# 3. Save scaler (SAMA)\n",
        "scaler_data = {\n",
        "    \"min\": scaler.data_min_.tolist(),\n",
        "    \"max\": scaler.data_max_.tolist(),\n",
        "    \"scale\": scaler.scale_.tolist(),\n",
        "    \"min_\": scaler.min_.tolist(),\n",
        "    \"feature_names\": features,\n",
        "    \"data_range\": scaler.data_range_.tolist()\n",
        "}\n",
        "\n",
        "with open(f'{backend_dir}/scaler_lstm.json', 'w') as f:\n",
        "    json.dump(scaler_data, f, indent=2)\n",
        "print(\"✅ Scaler saved\")\n",
        "\n",
        "# 4. Create model.json dengan CORRECT weight specs for LSTM(5,5)\n",
        "weights = model.get_weights()\n",
        "print(f\"🔍 Model weights info:\")\n",
        "for i, weight in enumerate(weights):\n",
        "    print(f\"  Weight {i}: {weight.shape}\")\n",
        "\n",
        "# Create EXACT weight specifications\n",
        "simple_model = {\n",
        "    \"format\": \"layers-model\",\n",
        "    \"generatedBy\": \"JasmaniAI 5-Month Predictor\",\n",
        "    \"convertedBy\": \"manual_5month_conversion\",\n",
        "    \"modelTopology\": {\n",
        "        \"keras_version\": \"2.15.0\",\n",
        "        \"backend\": \"tensorflow\",\n",
        "        \"model_config\": json.loads(model_json)\n",
        "    },\n",
        "    \"weightsManifest\": [{\n",
        "        \"paths\": [\"weights.bin\"],\n",
        "        \"weights\": [\n",
        "            {\"name\": \"lstm_layer/kernel\", \"shape\": list(weights[0].shape), \"dtype\": \"float32\"},\n",
        "            {\"name\": \"lstm_layer/recurrent_kernel\", \"shape\": list(weights[1].shape), \"dtype\": \"float32\"},\n",
        "            {\"name\": \"lstm_layer/bias\", \"shape\": list(weights[2].shape), \"dtype\": \"float32\"},\n",
        "            {\"name\": \"hidden_layer/kernel\", \"shape\": list(weights[3].shape), \"dtype\": \"float32\"},\n",
        "            {\"name\": \"hidden_layer/bias\", \"shape\": list(weights[4].shape), \"dtype\": \"float32\"},\n",
        "            {\"name\": \"output_layer/kernel\", \"shape\": list(weights[5].shape), \"dtype\": \"float32\"},\n",
        "            {\"name\": \"output_layer/bias\", \"shape\": list(weights[6].shape), \"dtype\": \"float32\"}\n",
        "        ]\n",
        "    }]\n",
        "}\n",
        "\n",
        "with open(f'{backend_dir}/model.json', 'w') as f:\n",
        "    json.dump(simple_model, f, indent=2)\n",
        "print(\"✅ model.json created\")\n",
        "\n",
        "# 5. Create weights.bin (SAMA)\n",
        "all_weights = np.concatenate([w.flatten() for w in weights])\n",
        "with open(f'{backend_dir}/weights.bin', 'wb') as f:\n",
        "    f.write(all_weights.astype(np.float32).tobytes())\n",
        "print(f\"✅ weights.bin saved ({len(all_weights):,} parameters)\")\n"
      ],
      "metadata": {
        "id": "PFRWtaCu4zaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Script ini menyimpan model yang telah dilatih ke dalam beberapa file untuk keperluan deployment. Bobot model disimpan dalam file model_weights.h5, sedangkan arsitektur model disimpan dalam file model_architecture.json. Selain itu, data scaler yang digunakan untuk normalisasi fitur disimpan dalam file scaler_lstm.json. Script juga membuat file model.json, yang berisi spesifikasi lengkap model, termasuk arsitektur dan informasi bobot, dengan format yang sesuai untuk TensorFlow.js. Terakhir, semua bobot model digabungkan dan disimpan dalam file weights.bin untuk memastikan kompatibilitas dengan berbagai platform. Langkah-langkah ini memastikan model siap digunakan dalam aplikasi backend atau frontend."
      ],
      "metadata": {
        "id": "8mV54t1X6z8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluasi"
      ],
      "metadata": {
        "id": "r36M_dsi7knO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n🧪 Testing prediction with 5-month input...\")\n",
        "\n",
        "# Test dengan sequence terakhir\n",
        "if len(X) > 0:\n",
        "    test_input = X[-1:].reshape(1, 5, 5)  # Shape: (1, 5, 5)\n",
        "    pred_scaled = model.predict(test_input, verbose=0)\n",
        "    pred_real = scaler.inverse_transform(pred_scaled)[0]\n",
        "\n",
        "    print(\"🔍 Test prediction (5 months → month 6):\")\n",
        "    for i, feat in enumerate(features):\n",
        "        print(f\"  {feat}: {pred_real[i]:.1f}\")\n",
        "\n",
        "# === Create test comparison data ===\n",
        "print(\"\\n📊 Creating test comparison data...\")\n",
        "test_comparisons = []\n",
        "\n",
        "# Get some real 6-month sequences for comparison\n",
        "for student_id, student_data in df.groupby('ID'):\n",
        "    try:\n",
        "        student_num = int(student_id[1:])\n",
        "        if len(student_data) >= 6:\n",
        "            student_data = student_data.sort_values('BULAN').reset_index(drop=True)\n",
        "            values = student_data[features].values\n",
        "\n",
        "            # Input: months 1-5, Target: month 6, Actual: month 6\n",
        "            input_5months = values[0:5]\n",
        "            actual_month6 = values[5]\n",
        "\n",
        "            # Predict month 6\n",
        "            input_scaled = scaler.transform(input_5months).reshape(1, 5, 5)\n",
        "            pred_scaled = model.predict(input_scaled, verbose=0)\n",
        "            pred_month6 = scaler.inverse_transform(pred_scaled)[0]\n",
        "\n",
        "            test_comparisons.append({\n",
        "                \"student_id\": student_id,\n",
        "                \"student_num\": student_num,\n",
        "                \"trend_type\": \"UP\" if student_num <= 250 else \"DOWN\",\n",
        "                \"input_months\": input_5months.tolist(),\n",
        "                \"actual_month6\": actual_month6.tolist(),\n",
        "                \"predicted_month6\": pred_month6.tolist(),\n",
        "                \"mae\": mean_absolute_error(actual_month6, pred_month6)\n",
        "            })\n",
        "\n",
        "            if len(test_comparisons) >= 10:  # First 10 students\n",
        "                break\n",
        "\n",
        "    except:\n",
        "        continue"
      ],
      "metadata": {
        "id": "bbXnA8CZ65OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Script ini menguji kemampuan model untuk memprediksi bulan ke-6 berdasarkan data 5 bulan sebelumnya. Pertama, script menggunakan sequence terakhir dari dataset untuk menghasilkan prediksi bulan ke-6, yang kemudian diubah kembali ke skala aslinya menggunakan scaler. Selanjutnya, script membuat data perbandingan dengan mengambil sequence 6 bulan dari data real untuk beberapa siswa. Lima bulan pertama digunakan sebagai input, sedangkan bulan ke-6 digunakan sebagai target aktual. Model memprediksi bulan ke-6, dan hasil prediksi dibandingkan dengan nilai aktual untuk menghitung Mean Absolute Error (MAE). Data perbandingan ini disimpan dalam bentuk dictionary untuk analisis lebih lanjut, dengan fokus pada 10 siswa pertama. Langkah ini memastikan evaluasi model dilakukan secara kuantitatif dan terukur."
      ],
      "metadata": {
        "id": "XQmtsNem7VdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'{backend_dir}/test_comparisons.json', 'w') as f:\n",
        "    json.dump(test_comparisons, f, indent=2)\n",
        "print(\"✅ Test comparisons saved\")\n",
        "\n",
        "# Show some comparison results\n",
        "print(\"\\n🔍 Sample Predictions vs Actual:\")\n",
        "for i, comp in enumerate(test_comparisons[:5]):\n",
        "    print(f\"\\n{comp['student_id']} ({comp['trend_type']} trend):\")\n",
        "    print(f\"  Actual month 6: {[round(x,1) for x in comp['actual_month6']]}\")\n",
        "    print(f\"  Predicted: {[round(x,1) for x in comp['predicted_month6']]}\")\n",
        "    print(f\"  MAE: {comp['mae']:.2f}\")\n",
        "\n",
        "# === Final report ===\n",
        "print(f\"\\n📁 Files created in {backend_dir}:\")\n",
        "total_size = 0\n",
        "for f in os.listdir(backend_dir):\n",
        "    size = os.path.getsize(f'{backend_dir}/{f}')\n",
        "    total_size += size\n",
        "    print(f\"  ✅ {f} ({size:,} bytes)\")\n",
        "\n",
        "print(f\"Total size: {total_size:,} bytes\")\n",
        "\n",
        "# === Model evaluation ===\n",
        "mae = mean_absolute_error(y.flatten(), model.predict(X, verbose=0).flatten())\n",
        "print(f\"\\n📊 Model Performance:\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"Training sequences: {len(X)}\")\n",
        "print(f\"Real data sequences: {len(X_real)}\")\n",
        "print(f\"Synthetic sequences: {len(synthetic_X)}\")\n",
        "\n",
        "print(\"\\n✅ MODEL SIAP! 5 Months Input → Month 6 Prediction!\")\n",
        "print(\"🎯 Model architecture SAMA dengan create_working_model\")\n",
        "print(\"📊 Input shape: (5, 5) - 5 months × 5 features\")\n",
        "print(\"📈 Output: 5 features untuk bulan ke-6\")\n",
        "print(\"🔥 Bisa bandingin prediksi vs data real bulan ke-6!\")\n",
        "\n",
        "print(\"\\n🚀 Next steps:\")\n",
        "print(\"1. cd ../backend\")\n",
        "print(\"2. node server.js\")\n",
        "print(\"3. Input 5 bulan data → dapat prediksi bulan ke-6\")\n",
        "print(\"4. Bandingin sama data real bulan ke-6\")\n",
        "\n",
        "print(f\"\\n🏁 Script completed successfully!\")"
      ],
      "metadata": {
        "id": "EtMziy8S7xqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Script ini menyimpan hasil perbandingan antara prediksi model dan data aktual bulan ke-6 ke dalam file test_comparisons.json untuk analisis lebih lanjut. Selain itu, script menampilkan beberapa contoh hasil prediksi versus data aktual, termasuk nilai Mean Absolute Error (MAE) untuk setiap siswa. Script juga memberikan laporan akhir tentang file yang dihasilkan, total ukuran file, dan performa model secara keseluruhan dengan menghitung MAE pada seluruh dataset pelatihan. Informasi seperti jumlah sequence pelatihan, sequence data real, dan sequence data sintetis juga ditampilkan. Langkah ini diakhiri dengan panduan untuk menjalankan model di backend.\n"
      ],
      "metadata": {
        "id": "ytigMZWM7y8f"
      }
    }
  ]
}