# -*- coding: utf-8 -*-
"""Capstone_Time_SeriesFIX.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RkCMRT6RWtsEpu3u6czdQ7EbRuSFtVr2
"""

pip install tensorflowjs

"""# Import Library"""

import pandas as pd
import numpy as np
import joblib

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error

from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense

"""- andas dan numpy digunakan untuk manipulasi data.

- MinMaxScaler dari sklearn digunakan untuk normalisasi data.

- Sequential, LSTM, dan Dense dari Keras digunakan untuk membangun dan melatih model LSTM.

- joblib bisa digunakan untuk menyimpan scaler jika diperlukan.

# Load Dataset
"""

# Load dataset
df = pd.read_csv('Data Garjas Unhan - Sheet1.csv')
df.head()

"""Dataset dimuat dari file CSV yang berisi data kebugaran jasmani dari beberapa individu. Data akan diproses lebih lanjut untuk memahami struktur dan isinya.

# Data Preparation & Preprocessing
"""

# Konversi kolom waktu
df['BULAN'] = pd.to_datetime(df['BULAN'], dayfirst=True)
df = df.sort_values('BULAN')
df.set_index('BULAN', inplace=True)

# Ambil kolom numerik (kecuali ID & NAMA)
numeric_cols = df.columns.difference(['ID', 'NAMA'])
df_numeric = df[numeric_cols]

# Normalisasi dan konversi format angka
scaler = MinMaxScaler()
for col in numeric_cols:
    df_numeric[col] = df_numeric[col].astype(str).str.replace(',', '.', regex=False)
    df_numeric[col] = pd.to_numeric(df_numeric[col], errors='coerce')

df_numeric.dropna(inplace=True)
scaled_data = scaler.fit_transform(df_numeric)

"""Data dibersihkan dan disiapkan untuk model:

- Kolom waktu diubah menjadi format datetime dan dijadikan index.

- Kolom numerik dipilih dan dikonversi dari string ke float.

- Nilai hilang dihapus.

- Data dinormalisasi agar semua fitur berada pada skala yang sama (0–1) menggunakan MinMaxScaler.

# Dataset Construction for LSTM
"""

def create_dataset(data, window_size=2):
    X, y = [], []
    for i in range(len(data) - window_size):
        X.append(data[i:i + window_size])
        y.append(data[i + window_size])
    return np.array(X), np.array(y)

window_size = 2
X, y = create_dataset(scaled_data, window_size)

"""# Model Building & Training"""

model = Sequential([
    LSTM(64, activation='relu', input_shape=(X.shape[1], X.shape[2])),
    Dense(df_numeric.shape[1])
])

model.compile(optimizer='adam', loss='mse')
model.fit(X, y, epochs=200, verbose=0)

"""# Prediction: Semua Data (Global Forecast)"""

# Ambil data paling akhir untuk prediksi selanjutnya
last_sequence = scaled_data[-window_size:]
last_sequence = last_sequence.reshape((1, window_size, df_numeric.shape[1]))

next_month_pred = model.predict(last_sequence)
next_month_pred = scaler.inverse_transform(next_month_pred)[0]

# Ambil ID terakhir (opsional)
last_id = df['ID'].iloc[-1] if 'ID' in df.columns else 'UNKNOWN'

# Tampilkan hasil prediksi
predicted_df = pd.DataFrame([next_month_pred], columns=df_numeric.columns)
predicted_df.insert(0, 'ID', last_id)

print("Prediksi bulan berikutnya:")
print(predicted_df)

"""Model digunakan untuk memprediksi data bulan selanjutnya berdasarkan urutan data terakhir dari seluruh dataset.
Prediksi di-inverse transform untuk mengembalikan data ke skala aslinya.

# Prediction Berdasarkan ID yang Dipilih
"""

input_id = input("Masukkan ID yang ingin diprediksi: ")
df_id = df[df['ID'] == input_id].copy()

if len(df_id) <= window_size:
    print(f"❌ Data untuk ID '{input_id}' tidak cukup untuk prediksi (minimal {window_size+1} baris).")
else:
    df_id = df_id.sort_index()
    df_id_numeric = df_id[numeric_cols]

    for col in df_id_numeric.columns:
        df_id_numeric[col] = df_id_numeric[col].astype(str).str.replace(',', '.', regex=False)
        df_id_numeric[col] = pd.to_numeric(df_id_numeric[col], errors='coerce')

    df_id_numeric.dropna(inplace=True)
    scaled_id_data = scaler.transform(df_id_numeric)

    last_sequence = scaled_id_data[-window_size:]
    last_sequence = last_sequence.reshape((1, window_size, df_id_numeric.shape[1]))

    pred_scaled = model.predict(last_sequence)
    pred = scaler.inverse_transform(pred_scaled)[0]

    predicted_df = pd.DataFrame([pred], columns=df_id_numeric.columns)
    predicted_df.insert(0, 'ID', input_id)

    print(f"\n📈 Prediksi bulan berikutnya untuk ID '{input_id}':")
    print(predicted_df)

"""# Prediction Berdasarkan Input Manual Terbaru"""

input_id = input("Masukkan ID yang ingin digunakan sebagai dasar prediksi: ")
df_id = df[df['ID'] == input_id].copy()
df_id = df_id.sort_index()

if len(df_id) < window_size - 1:
    print(f"❌ Data untuk ID '{input_id}' tidak cukup untuk ambil histori {window_size - 1} bulan.")
else:
    df_id_numeric = df_id[numeric_cols]
    for col in df_id_numeric.columns:
        df_id_numeric[col] = df_id_numeric[col].astype(str).str.replace(',', '.', regex=False)
        df_id_numeric[col] = pd.to_numeric(df_id_numeric[col], errors='coerce')

    df_id_numeric.dropna(inplace=True)

    base_sequence = df_id_numeric[-(window_size - 1):].values.tolist()

    print(f"\n📝 Masukkan data bulan terakhir (manual):")
    new_data = []
    for col in numeric_cols:
        val = input(f"  {col}: ").replace(',', '.')
        new_data.append(float(val))

    full_sequence = base_sequence + [new_data]
    full_sequence = np.array(full_sequence)

    scaled_sequence = scaler.transform(full_sequence)
    scaled_sequence = scaled_sequence.reshape((1, window_size, len(numeric_cols)))

    pred_scaled = model.predict(scaled_sequence)
    pred = scaler.inverse_transform(pred_scaled)[0]

    predicted_df = pd.DataFrame([pred], columns=numeric_cols)
    predicted_df.insert(0, 'ID', input_id)

    print(f"\n📈 Prediksi bulan selanjutnya untuk ID '{input_id}' berdasarkan input terbaru:")
    print(predicted_df)

"""Fitur lanjutan: pengguna dapat memasukkan data bulan terakhir secara manual, dan sistem akan memprediksi bulan berikutnya berdasarkan input ini serta histori sebelumnya dari ID yang dipilih."""

from google.colab import files
import shutil

# Zip folder agar bisa didownload
shutil.make_archive("tfjs_model", 'zip', "tfjs_model")
files.download("tfjs_model.zip")

import json

scaler_data = {
    "min": scaler.data_min_.tolist(),
    "max": scaler.data_max_.tolist(),
    "scale": scaler.scale_.tolist(),
    "min_": scaler.min_.tolist()
}

with open("scaler_lstm.json", "w") as f:
    json.dump(scaler_data, f)

files.download("scaler_lstm.json")